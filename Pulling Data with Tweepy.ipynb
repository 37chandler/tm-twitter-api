{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling Data with Tweepy\n",
    "\n",
    "**By:** _Jordan McNea_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tweepy\n",
    "\n",
    "# I've put my API keys in a .py file called API_keys.py\n",
    "from API_keys import api_key, api_key_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the Tweepy API\n",
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab follower IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had the WNBA Finals on in the background while creating this Notebook, so I will be collecting followers from the Seattle Storm and Las Vegas Aces, the two finalists. Tweepy only allows users to grab 900 requests per 15 minutes. It'll grab the 900 requests quickly then wait 15 minutes, rather than slowly grab 900 requests over a 15 minute period. Before we start grabbing follower IDs, let's first just check how long it will take. To do this we'll grab the followers_count item from Tweepy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm putting the handles in a list to iterate through below\n",
    "team_handles = ['seattlestorm', 'LVAces']\n",
    "\n",
    "\n",
    "# This will iterate through each Twitter handle that we're collecting from\n",
    "for screen_name in team_handles:\n",
    "    \n",
    "    # Tells Tweepy we want information on the handle we're collecting from\n",
    "    # The next line specifies which information we want, which in this case is the number of followers \n",
    "    user = api.get_user(screen_name) \n",
    "    followers_count = user.followers_count\n",
    "\n",
    "    # Let's see roughly how long it will take to grab all the follower IDs. \n",
    "    print(f'''\n",
    "    @{screen_name} has {followers_count} followers. \n",
    "    That will take roughly {followers_count/(5000*60):.0f} hours and {followers_count/(5000):.2f} minutes\n",
    "    ''')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there should only be one fifteen minute break. It'll grab all of the Storm's followers, then some of the Aces before sleeping for fifteen minutes. Let's run it and see how long it'll actually take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a dictionary containing a list for each Twitter handle we'll be grabbing follower IDs from\n",
    "id_dict = {'seattlestorm' : [],\n",
    "           'LVAces' : []}\n",
    "\n",
    "# Grabs the time when we start making requests to the API\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# .keys() allows us to iterate through each key in the dictionary\n",
    "for handle in id_dict.keys():\n",
    "    \n",
    "    # Each page contains 5,000 records, so since we know there are much more than 5,000 followers for both\n",
    "    # the Storm and Aces, we must iterate through each of the pages in order to get all follower IDs\n",
    "    # To grab the follower IDs, we will be using followers_ids\n",
    "    for page in tweepy.Cursor(api.followers_ids,\n",
    "                              # This is how we will get around the issue of not being able to grab all ids at once\n",
    "                              # Once the rate limit is hit, we will be notified that we must wait 15 mins (900 secs)\n",
    "                              wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True,\n",
    "                              screen_name=handle).pages():\n",
    "\n",
    "        # The page variable comes back as a list, so we have to use .extend rather than .append\n",
    "        id_dict[handle].extend(page)\n",
    "        \n",
    "\n",
    "# Let's see how long it took to grab all follower IDs\n",
    "end_time = datetime.datetime.now()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some ids we gathered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict['seattlestorm'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice they are all numbers. This is because ids are different from screen names. To see the twitter handles we gathered, we'll have to use the scren_name feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = id_dict['seattlestorm'][:10]\n",
    "\n",
    "for name in users:\n",
    "    \n",
    "    user = api.get_user(name)\n",
    "    print(user.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab descriptions based on the followers IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks much better. We can get all sorts of information from the ID. We don't just want screen names though, that doesn't tell us much. Let's grab each screen name and their description and write it to a text file for each team account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['screen_name','description']\n",
    "\n",
    "for team in id_dict.keys():\n",
    "    \n",
    "    # Descriptions with emoji or non-Roman letters can cause trouble. Encoding your .txt file in utf-8 will help\n",
    "    with open(f'{team}_followers.txt','w', encoding='utf-8') as out_file:\n",
    "        wf.write('\\t'.join(headers) + '\\n')\n",
    "\n",
    "        for idx, ids in enumerate(id_dict[team]):\n",
    "            \n",
    "            # For accounts set to private, we won't be able to get the description unless we follow them\n",
    "            # Putting in a try/except statement, we can get around this issue.\n",
    "            try:\n",
    "                user = api.get_user(ids)\n",
    "                description = str(user.description).replace('\\t',' ').replace('\\n',' ')\n",
    "                outline = [user.screen_name, user.description]\n",
    "                \n",
    "                out_file.write('\\t'.join([str(item) for item in outline]) + '\\n')\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            if idx == 100:\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing Tweets by search terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweepy also lets users grab tweets based off of search terms. October 10th was World Mental Health Day, so let's look at tweets containing its official hashtag. Twitter search allows standard search operators (<a href=\"https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/overview/standard-operators\">read more here</a>). We only want Tweets that occurred on World Mental Health Day, hence the since and until operators, and I'm excluding retweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the search API only goes back 7 days\n",
    "date_start = datetime.date.today()\n",
    "date_end = date_start - datetime.timedelta(days=2)\n",
    "\n",
    "search_words = f'#WorldMentalHealthDay since:{date_start} until:{date_end} -filter:retweets'\n",
    "\n",
    "# Notice the differences between searching tweets and users. \n",
    "for idx, item in enumerate(tweepy.Cursor(api.search,\n",
    "                   # tweet_mode is defaulted to short, which only holds the first 140 characters of a Tweet.\n",
    "                   tweet_mode='extended',\n",
    "                   q=search_words,\n",
    "                   lang='en').items()):\n",
    "    \n",
    "    # There's all sort of information you can get from Tweets\n",
    "    # Find more tweet objects here: https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object\n",
    "    print(item.user.screen_name)\n",
    "    print(item.created_at)\n",
    "    print(item.full_text)\n",
    "    print('-'*40)\n",
    "    \n",
    "    if idx == 50:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to use this search feature to grab the mentions of a Twitter account. Mentions are any tweet where another user's handle is included (i.e. they are mentioned in the tweet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = '@GovernorBullock -filter:retweets'\n",
    "\n",
    "\n",
    "tweets_all = tweepy.Cursor(api.search,\n",
    "                   tweet_mode='extended',\n",
    "                   q=search_words,\n",
    "                   lang='en').items()\n",
    "\n",
    "# Put all the Tweet objects for a single Tweet into a tuple, and put all those into a list\n",
    "tweets = [(tweet.full_text,tweet.created_at,tweet.user.screen_name) for tweet in tweets_all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
